# CSR과 SSR

## CSR

> Client Side Rendering

클라이언트 사이드 렌더링의 약자로, 브라우저에서 렌더링하는 방식

### 동작 방식

1. 사용자가 웹 페이지를 방문하면(request), 브라우저는 최소한의 HTML 파일을 다운로드(response) 한다. 이 HTML 파일은 `script`, `meta`, `link` 등의 태그를 포함하며, 빈 컨텐츠의 `index.html` 파일이라고 보면 된다.
2. 브라우저는 `index.html`에 있는 자바스크립트 번들 파일을 다운로드한 다음 AJAX를 통해 API 요청을 수행하여 동적 컨텐츠를 가져오고 파싱하여 최종 컨텐츠를 렌더링한다.
3. 사용자가 페이지를 이동할 경우, 서버에 추가 HTML파일을 요청하지 않고 이미 받은 자바스크립트를 이용하여 렌더링 한다.

### 장점

- 초기 로딩 속도가 빠르다.
- 서버의 부담이 적다. (필요한 부분만 요청하고 응답하기 때문에)
- 사용자 경험이 좋다. (깜빡임이 없다. 빠른 인터렉션을 제공한다.)

### 단점

- SEO(Search Engine Optimization)에 취약하다. (초기 HTML에는 빈 페이지만 존재하기 때문에 검색엔진이 페이지를 수집하기 어렵다.)
- 초기 로드 속도가 오래 걸린다. (첫 요청 시 필요한 모든 파일을 다운로드 받아야 하기 때문에)

#### SEO 최적화

- meta 태그를 넣어준다.
- sitemap 문서를 작성한다.
- 시맨틱 태그를 사용한다.
- 검색엔진에게 페이지를 수집할 수 있도록 robots.txt를 작성한다.

근데 사실 구글 크롤러는 자바스크립트를 실행시켜서 렌더링된 페이지를 수집한다. [네이버의 검색엔진](SPA 기반으로 제작된 사이트의 수집 및 색인을 지원)도 SPA 기반으로 제작된 사이트의 수집 및 색인을 지원하고 있다.

SEO가 아예 안되는 건 아니지만, 검색엔진마다 다르기 때문에 SEO를 잘 최적화 시켜주는 것이 좋다.

#### 초기 로드 속도 최적화

- 코드 스플리팅을 사용한다.

## SSR

> Server Side Rendering

서버사이드 렌더링의 약자로, 서버로부터 완전하게 만들어진 html파일을 받아와 페이지 전체를 렌더링하는 방식

### 동작 방식

1. 사용자가 웹 페이지를 방문하면(request), 서버는 리소스를 확인하고 페이지 내에 있는 서버측 스크립트를 실행 후 HTML 컨텐츠를 컴파일 및 준비한다.
2. 컴파일된 HTML은 추가 렌더링 및 표시를 위해 클라이언트 브라우저로 전송된다(response).
3. 브라우저는 HTML을 다운로드하고 최종 사용자가 사이트를 볼 수 있도록 한다.
4. 브라우저는 자바스크립트를 다운로드하고 실행하면서 페이지를 대화형(interactive)으로 만든다.
5. 클라이언트는 필요한 경우 추가적인 데이터를 서버로 요청하여 동적으로 페이지를 업데이트한다.

### 장점

- SEO에 유리하다. (서버에서 페이지를 넘겨받기 때문에 각 페이지에 대한 정보를 입력하기 쉽다.)
- 초기 로딩 속도가 빠르다. (서버로부터 화면을 렌더링 하기 위한 필수적인 요소를 먼저 가져오기 때문에)

### 단점

- 초기 로딩 이후 페이지 이동 시 속도가 느리다. (페이지 이동 시마다 서버로부터 새로운 페이지를 받아와야 하기 때문에)
  - TTV(Time To View)와 TTI(Time To Interact) 간의 시간 간격이 존재 (TTV < TTI)
- 서버의 부담이 크다. (사용자가 요청할 때마다 서버에서 페이지를 렌더링 해야 하기 때문에)
  - TTFB(Time To First Byte)가 길다.
- 사용자 경험이 좋지 않다. (페이지 이동 시마다 새로고침이 발생하기 때문에 깜빡임이 발생한다.)

#### 최적화

- 캐싱을 사용한다. (CDN을 사용한다.)
  - 동일한 요청에 대한 응답을 캐싱하여 서버의 부담을 줄인다. -> TTFB 감소, 렌더링 속도 증가



출처

- [왜 CSR에서 SEO가 단점일까?](https://minsoftk.tistory.com/68)
